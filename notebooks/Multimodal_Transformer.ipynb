{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nanopiero/exam_S3/blob/master/notebooks/Multimodal_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Atelier 4 : Régression multimodale avec un Visual Transformer\n"
      ],
      "metadata": {
        "id": "-1ciEeyNevrd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mU0zdFYCLdgR"
      },
      "outputs": [],
      "source": [
        "# Imports des bibliothèques utiles\n",
        "# pour l'IA\n",
        "import torch\n",
        "# pour les maths\n",
        "import numpy as np\n",
        "# pour afficher des images et des courbes\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/nanopiero/exam_S3.git"
      ],
      "metadata": {
        "id": "5zHe5if9b8Yn",
        "outputId": "f63816dc-c2a1-4038-fe83-00646a66c05b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'exam_S3'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 6 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (6/6), 19.86 KiB | 19.86 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install einops"
      ],
      "metadata": {
        "id": "ryjHWMbzMMGw",
        "outputId": "f56e6f8d-cad3-494e-ce18-49f84f9508fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m757.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A. Découverte du problème"
      ],
      "metadata": {
        "id": "iXg4IwvHDSyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans ce problème, il va s'agir de reconstruire un champ 2D à partir de plusieurs sources d'information. Les sources d'information sont les suivantes :\n",
        "  - des mesures ponctuelles du champ 2D non bruitées\n",
        "  - un prédicteur spatialisé, qui consiste en un champ 2D bruité.\n",
        "  - des mesures par tomographie obtenues le long de segments\n",
        "\n",
        "Le but est d'adapter et de comparer deux méthodes d'apprentissage différentes basées sur des réseaux de neurones profonds. Pour simplifier, nous allons travailler sur des données de synthèse générées à la volée.\n",
        "\n",
        "Ces données peuvent être visualisées grâce à la fonction gen_image_with_pairs."
      ],
      "metadata": {
        "id": "bDRbxFjVjckN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from exam_S3.utile_Transformers import voir_batch2D, gen_image_with_pairs, set_tensor_values\n",
        "\n",
        "batch_size = 6\n",
        "n_points = 16\n",
        "n_pairs = 16\n",
        "full_target, point_measurements, spatial_predictor, line_measurements_viz, line_measurements = gen_image_with_pairs(6, n_lines, n_points)\n",
        "# NB : Le code de gen_image_with_pairs est précompilé avec numba. Le premier run est donc nettement plus long que les suivants."
      ],
      "metadata": {
        "id": "pd1BiavmQnmO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exemples de champ 2D cible complets (full_target)\n",
        "# ils contiennent des disques, qu'il va s'agir de reconstruire au mieux\n",
        "fig1 = plt.figure(1, figsize=(36, 6))\n",
        "voir_batch2D(full_target, 6, fig1, k=0, min_scale=0, max_scale=1)"
      ],
      "metadata": {
        "id": "tjEfo2BprXx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pour reconstruire, on s'appuira sur des triplets contenant les positions et les\n",
        "# valeurs de mesures ponctuelles (point_measurements).\n",
        "# Précisément, ces triplets (x, y, m) contiennent :\n",
        "# - les coordonnées x, y des mesures ponctuelles dans le repère (O, A, B)\n",
        "# où O correspond au coin en bas à gauche de full_target, A au coin en bas à droite\n",
        "# et B au coin en haut à gauche.\n",
        "# - m : valeur au pixel de coordonnées (x,y) de full_target\n",
        "\n",
        "# Nous avons généré batch_size x n_points triplets :\n",
        "print(point_measurements.shape)\n",
        "\n",
        "# Pour visualiser ces mesures, on peut utiliser la fonction set_tensor_values(t,point_measurements, size):\n",
        "# qui affectent aux pixels de t de coordonnées x,y les valeurs m. Par exemple:\n",
        "point_measurements_viz = set_tensor_values(torch.zeros((6,1,64,64)), point_measurements, 64)\n",
        "fig2 = plt.figure(2, figsize=(36, 6))\n",
        "voir_batch2D(point_measurements_viz , 6, fig2, k=0, min_scale=0., max_scale=0.5)\n",
        "# NB: - bien noter le format utilisé pour le tenseur t\n",
        "#     - il y a bien 16 points par images, mais la plupart correspondent à des\n",
        "#       mesures nulles"
      ],
      "metadata": {
        "id": "K15fy_jnrmOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On s'appuiera aussi sur des prédicteurs spatialisés bruités.\n",
        "# Les rectangles figurent le bruit. Les disques contenus dans ces images\n",
        "# sont alignés avec ceux du champ 2D à reconstruire\n",
        "# mais leurs intensités sont différentes.\n",
        "\n",
        "fig3 = plt.figure(3, figsize=(36, 6))\n",
        "voir_batch2D(spatial_predictor, 6, fig3, k=0, min_scale=0, max_scale=1)\n"
      ],
      "metadata": {
        "id": "UInyun2vsh1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enfin, on s'appuie sur des mesures intégrées le long des segements contenus\n",
        "# dans des quintuplets\n",
        "# Précisément, ces quintuplets (x0, y0, x1, y1, Is) contiennent :\n",
        "# - les coordonnées x0, y0 de la première extrémité du segment\n",
        "# - les coordonnées x1, y1 de la seconde extrémité du segement\n",
        "# la valeur moyenne I du champ 2D full_target le long du segment\n",
        "\n",
        "\n",
        "# Nous avons ainsi généré batch_size x n_pairs quintuplets :\n",
        "print(line_measurements.shape)\n",
        "\n",
        "\n",
        "# Le tenseur line_measurements_viz permet de visualiser ces segments :\n",
        "fig3 = plt.figure(3, figsize=(36, 6))\n",
        "voir_batch2D(line_measurements_viz, 6, fig3, k=0, min_scale=0, max_scale=1)\n",
        "\n",
        "# NB: pour cette visualisation, les intensités des pixels par lesquels passent\n",
        "# les segements ont été réglées sur 0.2 + Is  (sauf aux intersections)"
      ],
      "metadata": {
        "id": "nJK99JkcvUga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B. Attendus"
      ],
      "metadata": {
        "id": "0vWPJFKbNkxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "gen_image_with_pairs permet d'aborder plusieurs problème d'apprentissage par plusieurs méthodes différentes.\n",
        "Pb n°1"
      ],
      "metadata": {
        "id": "fiR7Hym24P_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XUin-sed4NGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Annexe : exemple d'un visual transformer adapté au problème"
      ],
      "metadata": {
        "id": "Y5w49rrAPvAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paramètres du modèle :\n",
        "image_size = [64,64]\n",
        "channels = 1\n",
        "patch_size = 4\n",
        "d_model = 120\n",
        "mlp_expansion_ratio = 4\n",
        "d_ff = mlp_expansion_ratio * d_model\n",
        "n_heads = 4\n",
        "n_layers = 12"
      ],
      "metadata": {
        "id": "AGSx5D5Xr_MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Module interne du réseau responsable de l'encodage des variables :\n",
        "from PREAC.utile_Transformers import UnifiedEmbedding\n",
        "ue = UnifiedEmbedding(d_model, patch_size, channels)\n",
        "lamedeau, pluviometres, radar, cmls_spatialises, cmls = gen_image_with_pairs(6, n_pairs, n_points)\n",
        "embeddings = ue(radar, pluviometres, cmls)\n",
        "print(embeddings.shape)\n"
      ],
      "metadata": {
        "id": "bhL3zpLWQatB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from exam_S3.utile_Transformers import FusionTransformer\n",
        "model = FusionTransformer(image_size, patch_size, n_layers, d_model, d_ff, n_heads, channels=1)\n",
        "lamedeau, pluviometres, radar, cmls_spatialises, cmls = gen_image_with_pairs(6, n_pairs, n_points)\n",
        "model(radar, pluviometres, cmls).shape\n",
        "\n",
        "\n",
        "def criterion(output, target):\n",
        "    return torch.abs((output - target)).mean()\n",
        "\n",
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters(), 10**(-4))"
      ],
      "metadata": {
        "id": "yUrHDDikx0on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## E. Chargement d'un Transformer entraîné"
      ],
      "metadata": {
        "id": "46iifY4CTclo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Avec France Transfert ??\n",
        "# !curl 'https://francetransfert.numerique.gouv.fr/api-private/download-module/generate-download-url' -X POST \\\n",
        "# -H 'Content-Type: application/json' \\\n",
        "# -H 'Origin:https://francetransfert.numerique.gouv.fr' \\\n",
        "# --data-raw '{\"enclosure\":\"164ea132-cf5e-4a8d-a084-62841b3122ec\",\"recipient\":\"cGllcnJlLmxlcGV0aXRAbWV0ZW8uZnI%3D\",\"token\":\"ddf68980-7b19-4eef-8a34-88a3e32a0f71\",\"senderToken\":null,\"password\":\"2q*vbl62!FK@Z\"}'"
      ],
      "metadata": {
        "id": "YJCqiOB8X574"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modèles entraînés sur 900 époques :\n",
        "# mViT_900ep.pth comme au D.\n",
        "# mViT_0radar_900ep.pth avec, au préalable: radar = 0 x radar\n",
        "! wget https://www.grosfichiers.com/K3aaxZcSnX4_Fic8rPjJ9yZ\n",
        "! unzip K3aaxZcSnX4_Fic8rPjJ9yZ\n",
        "! rm K3aaxZcSnX4_Fic8rPjJ9yZ"
      ],
      "metadata": {
        "id": "Mte3Iwt0XVtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bibliographie :  [Jaegle et al. 2020](https://arxiv.org/abs/1811.12739)"
      ],
      "metadata": {
        "id": "Asx8jHYKU7wL"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}